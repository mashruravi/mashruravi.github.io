{"componentChunkName":"component---src-components-blog-layout-js","path":"/blog/2021-07-05-mnist-baseline/","result":{"data":{"mdx":{"id":"52f47cf6-7175-5252-b66b-6629dd961f16","body":"function _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\nvar _frontmatter = {\n  \"title\": \"MNIST Baseline using Pixel Similarity\",\n  \"date\": \"2021-07-05T00:00:00.000Z\"\n};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, [\"components\"]);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(Image, {\n    name: \"MNIST_Baseline_pixel_similarity.png\",\n    mdxType: \"Image\"\n  }), mdx(\"h1\", null, \"Baseline for MNIST Handwritten Digit Classification using Pixel Similarity\"), mdx(\"p\", null, \"To create a baseline model for the MNIST handwritten digits classification problem, we expand the approach used in \", mdx(\"a\", _extends({\n    parentName: \"p\"\n  }, {\n    \"href\": \"https://github.com/fastai/fastbook/blob/master/04_mnist_basics.ipynb\"\n  }), \"chapter 4 of fastbook\"), \".\"), mdx(\"p\", null, \"In the book, the average pixel value for every pixel of two numbers - 3 and 7 is calculated. The pixel values of images in the test set are then compared to these averages (using the L1-norm and the RMSE values) and the digit is classified as the average to which the new image is \\\"closer\\\".\"), mdx(\"p\", null, \"We can use the same approach to calculate the average pixel value of every pixel for each of the 10 digits in the MNIST handwritten digits dataset. This gives us 10 \\\"mean pixel images\\\". And then for each image in the test set, we calculate the distance of its pixels from each of the 10 mean pixel images and classify the image as the one from which it is the shortest distance away.\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"from fastai.vision import *\\n\")), mdx(\"p\", null, \"First, we download and extract the entire MNIST handwritten digits dataset instead of the sample dataset.\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"path = untar_data(URLs.MNIST)\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {}), \"Downloading https://s3.amazonaws.com/fast-ai-imageclas/mnist_png.tgz\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"path.ls()\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {}), \"[PosixPath('/root/.fastai/data/mnist_png/testing'),\\n PosixPath('/root/.fastai/data/mnist_png/training')]\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"training_paths = [(path/'training'/str(i)) for i in range(10)]\\ntesting_paths = [(path/'testing'/str(i)) for i in range(10)]\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"training_paths\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {}), \"[PosixPath('/root/.fastai/data/mnist_png/training/0'),\\n PosixPath('/root/.fastai/data/mnist_png/training/1'),\\n PosixPath('/root/.fastai/data/mnist_png/training/2'),\\n PosixPath('/root/.fastai/data/mnist_png/training/3'),\\n PosixPath('/root/.fastai/data/mnist_png/training/4'),\\n PosixPath('/root/.fastai/data/mnist_png/training/5'),\\n PosixPath('/root/.fastai/data/mnist_png/training/6'),\\n PosixPath('/root/.fastai/data/mnist_png/training/7'),\\n PosixPath('/root/.fastai/data/mnist_png/training/8'),\\n PosixPath('/root/.fastai/data/mnist_png/training/9')]\\n\")), mdx(\"p\", null, \"We then convert the images to tensors.\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"training_tensors = [torch.stack([open_image(l).data[0] for l in p.ls()]) for p in training_paths]\\ntesting_tensors = [torch.stack([open_image(l).data[0] for l in p.ls()]) for p in testing_paths]\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"len(training_tensors), len(testing_tensors)\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {}), \"(10, 10)\\n\")), mdx(\"p\", null, \"We now calculate the mean value of each pixel for each of the digits, using the images in the training set.\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"mean_tensors = [tr.mean(0) for tr in training_tensors]\\nmean_images = [Image(1 - mtr.repeat(3, 1, 1)) for mtr in mean_tensors]\\nshow_all(mean_images)\\n\")), mdx(\"p\", null, \"\\u200B\", mdx(\"br\", {\n    parentName: \"p\"\n  }), \"\\n\", mdx(\"img\", _extends({\n    parentName: \"p\"\n  }, {\n    \"src\": \"MNIST_Baseline_files/MNIST_Baseline_11_0.png\",\n    \"alt\": \"png\"\n  })), \"\\n\\u200B    \"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"testing_tensors[0].shape, mean_tensors[0].shape\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {}), \"(torch.Size([980, 28, 28]), torch.Size([28, 28]))\\n\")), mdx(\"p\", null, \"We then iterate over every image in the test set and calculate their distance from each of the 10 images we generated above. We use RMSE to calculate the distance.\"), mdx(\"p\", null, \"We keep track of how many images are correctly classified using the \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"correct\"), \" list and the total number of images in the class using the \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"total\"), \" list.\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"correct = []\\ntotal = []\\n\\nfor i in range(10):\\n  total.append(testing_tensors[i].shape[0])\\n  preds = torch.Tensor([\\n          torch.stack(\\n              [\\n                F.mse_loss(testing_tensors[i][imgidx], mean_tensors[midx]).sqrt()\\n                for midx in range(10)\\n              ]\\n            ).argmin()\\n            for imgidx in range(testing_tensors[i].shape[0])\\n        ])\\n\\n  correct.append((preds == i).sum())\\n\\ncorrect, total\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {}), \"([tensor(878),\\n  tensor(1092),\\n  tensor(781),\\n  tensor(814),\\n  tensor(811),\\n  tensor(612),\\n  tensor(827),\\n  tensor(856),\\n  tensor(718),\\n  tensor(814)],\\n [980, 1135, 1032, 1010, 982, 892, 958, 1028, 974, 1009])\\n\")), mdx(\"p\", null, \"We can then sum the count of correct predictions for each class and divide that by the total number of images in the test set to get the accuracy of this baseline model.\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"torch.Tensor(correct).sum(), torch.Tensor(total).sum()\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {}), \"(tensor(8203.), tensor(10000.))\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"print('Accuracy: ', torch.Tensor(correct).sum()/torch.Tensor(total).sum())\\n\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {}), \"Accuracy:  tensor(0.8203)\\n\")), mdx(\"p\", null, \"This baseline model gives us an accuracy of 82.03% on this dataset.\"));\n}\n;\nMDXContent.isMDXComponent = true;","frontmatter":{"title":"MNIST Baseline using Pixel Similarity"}}},"pageContext":{"id":"52f47cf6-7175-5252-b66b-6629dd961f16"}},"staticQueryHashes":["3069025275","63159454"]}